
---

### Here, we will consider whether newly announced RL methods can be executed in the open r1 environment from 2025.

### We have already confirmed that GRPO, CPPO, DRGRPO, and DRGRPO+CPPO can be executed in the original environment.

### We are currently preparing RAFTvanilla and RAFT++.

---

### GRPO, CPPO, DRGRPO, DRGRPO+CPPO with gsm
grpo_gsm.py, grpo__trainer_gsm.py

### RAFTvanilla and RAFT++ with gsm
grpo_gsm_raft.py, grpo_trainer_gsm_raft.py

---

### The following literature is of interest:

#### CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models (cppo)
https://arxiv.org/abs/2503.22342

#### Understanding R1-Zero-Like Training: A Critical Perspective (drgrpo)
https://arxiv.org/abs/2503.20783

#### A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce (raft)
https://arxiv.org/abs/2504.11343

#### REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models (reinforce)
https://arxiv.org/abs/2501.03262

---
